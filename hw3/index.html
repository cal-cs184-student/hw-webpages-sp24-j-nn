<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Project 3: Pathtracer</title>
<style>
  body {
    margin: 20px;
  }
  h1, h2, h3 {
    margin-left: 50px;
	text-align: left;
  }
  p {
    padding: 0 50px;
  }
  .image-container {
    display: flex;
    justify-content: space-between;
    margin-bottom: 20px;
  }
  .image-container img {
    width: 80%;
    height: auto;
    display: block;
    margin: 0 auto;
  }
  .caption {
	margin-top: 15 px;
    text-align: center;
  }
</style>
</head>
<body>

<h1>Project 3: Pathtracer</h1>

<h2>Part 1: Ray Generation and Scene Intersection</h2>

<h3>Explanation of Ray Generation</h3>
<p> We begin by converting the pixel coordinates to represent the position within the image plane
  and are normalized to the range [0, 1], which is then transformed into camera coordinates.
  We use the function ('tan') to calculate horizontal and vertical offsets from the center of the 
  plane. Then the camera-to-world transformation matrix ('c2w') is applied to the camera coordinates
  so we can obtain the direction of the ray in world space. The resulting direction vector is normalized,
  the generated ray is constructed with its origin at the camera position ('pos'), and its direction is set
  to the computed ray direction. 
</p>

<h3>Explanation of Triangle/Sphere Intersection</h3>
<p> In the functions bool Triangle::has_intersection and bool Sphere::has_intersection, we are determining
  whether a ray intersects with a triangle using barycentric coordinates. In the class Triangle, it calculates the
  intersection point and checks if it's within the boundaries, returning true if so. While in Sphere, the 
  function checks whether a ray interects with a sphere by solving the quadratic equation derived from the
  ray's equation and the sphere's implicit equation.
</p>

<div class="image-container">
  <div>
    <img src="images/part1_ray_triangle.png" alt="Image 1">
    <div class="caption">Triangle.</div>
  </div>
  <div>
    <img src="images/part1_ray_sphere.png" alt="Image 2">
    <div class="caption">Sphere</div>
  </div>
  <div>
    <img src="images/part1_ray_coil.png" alt="Image 3">
    <div class="caption">Coil</div>
  </div>
</div>

<h2>Part 2: Bounding Volume Hierarchy</h2>
<h3>BVH Construction</h3>
<p>The algorithm recursively builds the BVH tree, and for each step we determine whether to create
	a leaf or internal node based on number of primitives and the maximum leaf size. If the number of
	nodes are less than or equal to the maximum leaf size or leaf node created, we enclose all the
	primitives within a bounding box. Otherwise, the internal node is created by splitting the primitives
	along the longest axis of their bounding box. The splitting point is chosen by finding the axis with
	the maximum extent and then sorting the primitives of their centroids along that axis. We keep doing this 
	until we reach the specified maximum leaf size.
</p>

<h3>Splitting Point Heuristic</h3>
<p>We pick the splitting point by balancing the number of primitives in each child node and minimizing
	the overlap between them. The algo selects the axis with the max extent along the three dimensions (x, y, z)
	of the bounding box. Then, it sorts the primitives based on their centroids along the axis and splits them
	into two groups, which makes sure each group has approximtaely equal number of primitives. 
</p>
<h3>Normal Shading</h3>
<p>By shading surfaces based on their surface normal, these images show how light interacts with the geometries 
	and highlight subtle variations in surface orientation. Normal shading enhances the realism of rendered scenes 
	thus simulate how light would act with surfaces.
</p>


<h3>Rendering Experiments</h3>
<p>We can see below that without BVH acceleration, it is much more efficient as we are reducing ray intersection
	computations. Thus, we are able to generate faster images that are still high-quality.
</p>

<div class="image-container">
	<div>
		<img src="images/part2_beast.png" alt="Image 1">
		<div class="caption">With BVH: 0.0488s, 3.1435 million rays per second, and 5.110071 intersection tests per ray.
			Without BVH: 19.9849s, 0.0174 million rays per second, and 3172.602997 intersection tests per ray.
		</div>
	<div>
		<img src="images/part2_wall_e.png" alt="Image 2">
		<div class="caption"> With BVH: 0.0704s, 3.4442 million rays per second, 10.198931 intersection tests per ray.
		  Without BVH: 90.8991s, 0.0040 million rays per second, and 7707.931367 intersection tests per ray.
		</div>
	<div>
		<img src="images/part2_CBlucy.png" alt="Image 3">
		<div class="caption"> With BVH: 0.0442s, 3.3153 million rays per second, 5.585757 intersection tests per ray.
			Without BVH: 46.4878s, 0.0078 million rays per second, 3703.193595 intersection tests per ray.
		</div>
  </div>

<h2>Part 3: Direct Illumination</h2>

<h3>Uniform hemisphere sampling</h3>
<h3>Light important sampling</h3>

<h2>Part 4: Global Illumination</h2>
<!-- Content for Part 4 goes here -->

<h2>Part 5: Adaptive Sampling</h2>
<!-- Content for Part 5 goes here -->

</body>
</html>